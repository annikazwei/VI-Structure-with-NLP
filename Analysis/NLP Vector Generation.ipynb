{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install huggingface\n",
    "!pip install transformers\n",
    "\n",
    "#install sentencepiece (tokenizer used by some language models---GPT, DeBERTa V2)\n",
    "!pip install sentencepiece\n",
    "!wget https://raw.githubusercontent.com/google/sentencepiece/master/data/botchan.txt\n",
    "\n",
    "#install the version of sklearn that supports varimax rotation in factor analysis\n",
    "!pip uninstall scikit-learn -y\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning / NLP\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer #AutoModelForMaskedLM\n",
    "\n",
    "# Basic Operations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting Results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matrix Factorization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FactorAnalysis, KernelPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Loading Function\n",
    "def load_model(model_name=\"roberta\"):\n",
    "   model = AutoModel.from_pretrained(models[model_name][0], output_attentions=False)\n",
    "   tokenizer = AutoTokenizer.from_pretrained(models[model_name][1], use_fast=False)\n",
    "\n",
    "   device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "   model.to(device)\n",
    "\n",
    "   # grab the  mask token\n",
    "   mask_token = tokenizer.mask_token\n",
    "\n",
    "   return model, tokenizer, mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Functions\n",
    "def embed_w_batches(sentences, tokenizer, model, device, mask=True, verbose=False, batch_size=256):\n",
    "   # Empty GPU cache\n",
    "   torch.cuda.empty_cache()\n",
    "\n",
    "   def chunks(lst, n):\n",
    "       for i in range(0, len(lst), n):\n",
    "           yield lst[i:i + n]\n",
    "   embedding = []\n",
    "\n",
    "   for i, sentence_batch in enumerate(chunks(sentences, batch_size)):\n",
    "       if verbose: print(f\"Sample: {i*batch_size}\")\n",
    "       embedding += list(embed_sentences(sentence_batch, tokenizer, model, device, mask=mask, verbose=verbose))\n",
    "   return np.array(embedding)\n",
    "\n",
    "def embed_sentences(sentences, tokenizer, model, device, mask=True, verbose=False):\n",
    "   inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True).to(device)\n",
    "   outputs = model(**inputs)\n",
    "   embedding = outputs.last_hidden_state.cpu().detach().numpy()\n",
    "\n",
    "   if mask == True:\n",
    "       mask_idx = inputs[\"input_ids\"] == tokenizer.mask_token_id\n",
    "       mask_idx = mask_idx.cpu()\n",
    "       embed_temp = []\n",
    "\n",
    "       for i in range(embedding.shape[0]):\n",
    "           embed_row = embedding[i, mask_idx[i], :].squeeze()\n",
    "           if len(embed_row.shape) > 1:\n",
    "               embed_row = embed_row.mean(axis=0)\n",
    "           embed_temp += [embed_row]\n",
    "       embedding = np.array(embed_temp)\n",
    "\n",
    "   if mask == False:\n",
    "       mask_idx = None\n",
    "       embedding = embedding[:, 0, :].squeeze()\n",
    "\n",
    "   # clean up the memory on GPU\n",
    "   del inputs, outputs, mask_idx\n",
    "   torch.cuda.empty_cache()\n",
    "\n",
    "   return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annikawei/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "   \"bert\": (\"bert-base-uncased\", \"bert-base-uncased\"),\n",
    "   \"deberta\": (\"microsoft/deberta-large\", \"microsoft/deberta-large\"),\n",
    "   \"bart\" : [\"facebook/bart-large-mnli\", \"facebook/bart-large-mnli\", 256], #(only give one mask token)\n",
    "   \"deberta-l-mnli\" : [\"Narsil/deberta-large-mnli-zero-cls\", \"Narsil/deberta-large-mnli-zero-cls\", 128]\n",
    "}\n",
    "\n",
    "# download language model\n",
    "model_name = \"deberta-l-mnli\"\n",
    "model, tokenizer, mask_token = load_model(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load SETPOINT Dimensions\n",
    "\n",
    "*Note:* Instead of defining SETPOINT with dimension names, we utilized a short description of each dimension to provide a clearer explanation to language models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETPOINT Dimension Description\n",
    "dimensions = [\n",
    "   \"the application of science to life, medicine, and health\", \n",
    "   \"the expression of imaginative and creative ideas\", \n",
    "   \"problem-solving, innovation, and creation of technology\", \n",
    "   \"working with, helping people, and understanding people\", \n",
    "   \"planning and organizing in structured business environments\", \n",
    "   \"leading, persuading, and influencing other people\", \n",
    "   \"agriculture, outdoors, and nature\",\n",
    "   \"mechanical, hands-on, and physical activities\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Query for Dimensions\n",
    "DM_query = [f\"A career in {mask_token} {mask_token} is aligned with a general interest in activities that involve {category}.\" for category in dimensions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0\n"
     ]
    }
   ],
   "source": [
    "# Embedding Query for Dimensions\n",
    "DM_vectors = embed_w_batches(DM_query, tokenizer, model, device, verbose=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Dimension Vectors to Dataframe\n",
    "DM_vectors_df = pd.DataFrame(DM_vectors, index = dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load SETPOINT Basic Interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETPOINT Basic Interests\n",
    "basic_interest = {\n",
    "   \"Health Science\": [\"life science\", \"medical science\", \"health care service\"],\n",
    "   \"Creative Expression\": [\"media\", \"applied arts and design\", \"music\", \"visual arts\",\n",
    "                           \"performing arts\", \"creative writing\", \"culinary art\"],\n",
    "   \"Technology\": [\"engineering\", \"physical science\", \"information technology\", \"mathematics or statistics\"],\n",
    "   \"People\": [\"social science\", \"humanities or foreign language\", \"teaching or education\",\n",
    "              \"social service\", \"religious activities\"],\n",
    "   \"Organization\": [\"human resources\", \"personal service\", \"accounting\", \"office work\", \"finance\"],\n",
    "   \"Influence\": [\"management or administration\", \"business initiatives\", \"marketing or advertising\", \"professional advising\", \"public speaking\", \"sales\",\n",
    "                \"politics\", \"law\"],\n",
    "   \"Nature\": [\"agriculture\", \"outdoors\", \"animal service\"],\n",
    "   \"Things\": [\"mechanics or electronics\", \"transportation or machine operation\",\n",
    "              \"construction or woodwork\", \"physical or manual labor\", \"athletics\",\n",
    "              \"protective service\"]\n",
    "}\n",
    "\n",
    "# Flatten  Descriptors\n",
    "basic_interests = [desc for sublist in basic_interest.values() for desc in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Interst Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Query for Basic Interests\n",
    "queries = [f\"A career in [MASK][MASK] is aligned with {descriptor} interests.\" for descriptor in basic_interests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0\n"
     ]
    }
   ],
   "source": [
    "# Embedding Query for Basic Interests\n",
    "BI_vectors = embed_w_batches(queries, tokenizer, model, device, verbose=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors have been saved to /Users/annikawei/Desktop/work/vocational interest project/data/bi_vectors.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert Basic Interest Vectors to Dataframe\n",
    "BI_vectors_df = pd.DataFrame(BI_vectors, index = basic_interests)\n",
    "\n",
    "csv_file_path = \"/Users/annikawei/Desktop/work/vocational interest project/data/bi_vectors.csv\"\n",
    "BI_vectors_df.to_csv(csv_file_path)\n",
    "\n",
    "print(f\"Vectors have been saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
